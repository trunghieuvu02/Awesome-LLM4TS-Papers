# Awesome-LLM4TS-Papers
Welcome to Awesome-LLM4TS-Papers! This repository is designed to be a comprehensive resource for researchers and practitioners 
interested in the intersection of large language models (LLMs) and time series data. It lists and categorizes papers from 
leading conferences: NeurIPS, ICLR, ICML, WWW, AAAI, and top journals in the field of machine learning (TMLR)

## ðŸš€ Updates

- **2025-02-25**: Repository created! ðŸŽ‰


| Title                                                                                   |                        Publisher                        |                           Code                        |
|:----------------------------------------------------------------------------------------|:-------------------------------------------------------:|:-----------------------------------------------------:| 
| Position: What Can Large Language Models Tell Us about Time Series Analysis             |      [ICML 2024](https://arxiv.org/abs/2402.02713)      |                            -                          |
| Multi-Patch Prediction: Adapting LLMs for Time Series Representation Learning           |      [ICML 2024](https://arxiv.org/abs/2402.04852)      |       [Code](https://github.com/yxbian23/aLLM4TS)     |
| S^2IP-LLM: Semantic Space Informed Prompt Learning with LLM for Time Series Forecasting | [ICML 2024](https://openreview.net/forum?id=qwQVV5R8Y7) |     [Code](https://github.com/panzijie825/S2IP-LLM)   | 
| Time-LLM: Time Series Forecasting by Reprogramming Large Language Models                |      [ICML 2024](https://arxiv.org/abs/2310.01728)      |       [Code](https://github.com/KimMeen/Time-LLM)     | 
| TEMPO: Prompt-based Generative Pre-trained Transformer for Time Series Forecasting      |      [ICML 2024](https://arxiv.org/abs/2310.04948)      |       [Code](https://github.com/DC-research/TEMPO)    |
| Unified Training of Universal Time Series Forecasting Transformers                      |     [ICML 2024](https://arxiv.org/abs/2402.02592)       | [Code](https://github.com/SalesforceAIResearch/uni2ts)|
| UniTime: A Language-Empowered Unified Model for Cross-Domain Time Series Forecasting    |      [WWW 2024](https://arxiv.org/abs/2310.09751)       |        [Code](https://github.com/liuxu77/UniTime)     |
| MC-ANN: A Mixture Clustering-Based Attention Neural Network for Time Series Forecasting | [TPAMI 2025](https://ieeexplore.ieee.org/abstract/document/10979493) | None |
| VisionTS: Visual Masked Autoencoders Are Free-Lunch Zero-Shot Time Series Forecasters   | [ICML 2025](https://arxiv.org/abs/2408.17253) | [Code](https://github.com/Keytoyze/VisionTS) |




